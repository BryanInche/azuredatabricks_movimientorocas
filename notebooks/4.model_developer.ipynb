{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78c15d4a-d893-483b-9785-ffa2609918c1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.notebook.run(\"Delete Experiment\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03ee70a6-a9bd-4886-be5c-f42338b9cef8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_delta = spark.read.format(\"delta\").load(\"/mnt/datalakemlopsd4m/processed/datmarcobre_featureengineer_delta\")\n",
    "df_delta.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a3142e1-0deb-446f-a302-1ae729e935e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos = df_delta.toPandas()\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97ea9309-2b3b-4772-9e17-77be120a2d31",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow hyperopt fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "063e75e3-48a1-4e46-a7f1-9c361ee98c95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.model_selection\n",
    "import sklearn.ensemble\n",
    "\n",
    "#gf\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import mlflow.tensorflow\n",
    "from hyperopt import fmin, tpe, hp, SparkTrials, Trials, STATUS_OK\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Normalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b39fee1-d9c3-4b3f-9ec7-402b68f3c1dc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos['numero_pases_carguio'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65d5c893-33d6-41d4-b0ae-65ba57e03573",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Supongamos que datos es tu DataFrame y has seleccionado tus características (X) y variable objetivo (y)\n",
    "X = datos[['capacidad_en_volumen_equipo_carguio_m3',\n",
    "'capacidad_en_peso_equipo_carguio',\n",
    "'capacidad_en_peso_equipo_acarreo',\n",
    "'densidad_inicial_poligono_creado_tn/m3',\n",
    "'capacidad_en_volumen_equipo_acarreo_m3']].values\n",
    "\n",
    "y = datos['numero_pases_carguio'].values # Reemplaza 'variable_objetivo' con el nombre de tu variable objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b517693-84f5-4b77-981b-035f51a5c98d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e5b7a7f-b6b5-4623-afa7-d07c35116c33",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Part 1. Train a classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c276c2c-b965-4814-ba1c-f39e88032087",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### MLflow Tracking\n",
    "[MLflow tracking](https://www.mlflow.org/docs/latest/tracking.html) allows you to organize your machine learning training code, parameters, and models. \n",
    "\n",
    "You can enable automatic MLflow tracking by using [*autologging*](https://www.mlflow.org/docs/latest/tracking.html#automatic-logging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4386cf16-81d9-4744-ade2-c6fce039c92f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Establecer semillas en NumPy y TensorFlow\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train_rnn, X_test_rnn, y_train_rnn, y_test_rnn = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52327a5a-c038-4aa0-b324-57be115e2a37",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Modelo 1 - Redes LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc3d9399-c2dd-4751-b3f6-b764be691e8d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Librerias para redes neuronales(LSTM)\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Normalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Establecer semillas en NumPy y TensorFlow\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train_rnn, X_test_rnn, y_train_rnn, y_test_rnn = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#X_train_rnn, X_test_rnn, y_train_rnn, y_test_rnn = train_test_split(X_array, y_array, test_size=0.2, random_state=42)\n",
    "\n",
    "model_rnn = Sequential()\n",
    "# La forma de entrada para LSTM debe ser (n_timesteps, n_features)\n",
    "model_rnn.add(LSTM(30, activation='relu', input_shape=(1, 5)))  #  (n_samples, n_pasos, n_variables)\n",
    "# Agregar capas Dense según sea necesario\n",
    "model_rnn.add(Dense(60, activation='relu'))\n",
    "model_rnn.add(Dense(30, activation='relu'))\n",
    "model_rnn.add(Dense(15, activation='relu'))\n",
    "# Capa de salida\n",
    "model_rnn.add(Dense(1, activation='linear'))\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Compilar el modelo\n",
    "model_rnn.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# Imprimir un resumen del modelo\n",
    "model_rnn.summary()\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model_rnn.fit(X_train_rnn.reshape(-1, 1, 5), y_train_rnn, epochs=1, validation_data=(X_test_rnn.reshape(-1, 1, 5),y_test_rnn), batch_size=5, verbose=1)\n",
    "\n",
    "# VALIDACION 1\n",
    "# Obtener la pérdida en el conjunto de entrenamiento y el conjunto de validación\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Calcular el RMSE en el conjunto de entrenamiento y el conjunto de validación\n",
    "train_rmse = np.sqrt(train_loss)\n",
    "val_rmse = np.sqrt(val_loss)\n",
    "\n",
    "# VALIDACION 2\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "y_pred_rnn = model_rnn.predict(X_test_rnn.reshape(-1, 1, 5)) # (n_samples, n_pasos, n_variables)\n",
    "\n",
    "# Redondear los valores de y_pred al entero más cercano\n",
    "y_pred_rnn = np.round(y_pred_rnn).astype('int64')\n",
    "\n",
    "# Calcular el error cuadrático medio en el conjunto de prueba\n",
    "mse = mean_squared_error(y_test_rnn, y_pred_rnn)\n",
    "# Calcular la raíz cuadrada del error cuadrático medio\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'Raíz del Error Cuadrático Medio en el conjunto de prueba: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8764ef5f-a1da-44a1-ad9f-81dd9fd0fd06",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.keras\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Establecer semillas en NumPy y TensorFlow\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train_rnn, X_test_rnn, y_train_rnn, y_test_rnn = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#MLflow podra registrar automáticamente métricas, parámetros y el modelo generado durante el entrenamiento\n",
    "mlflow.tensorflow.autolog()  # Keras y TensorFlow\n",
    "\n",
    "# Entrenar el modelo\n",
    "with mlflow.start_run(run_name='experimento_MLOPS_V1'):  #Iniciliza un nuevo experimento de MlFlow\n",
    "    # Definir y compilar el modelo\n",
    "    model_rnn = Sequential()\n",
    "    model_rnn.add(LSTM(30, activation='relu', input_shape=(1, 5)))\n",
    "    model_rnn.add(Dense(60, activation='relu'))\n",
    "    model_rnn.add(Dense(30, activation='relu'))\n",
    "    model_rnn.add(Dense(15, activation='relu'))\n",
    "    model_rnn.add(Dense(1, activation='linear'))\n",
    "\n",
    "    model_rnn.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    # Entrenar el modelo y guardar el historial del entrenamiento\n",
    "    history = model_rnn.fit(X_train_rnn.reshape(-1, 1, 5), y_train_rnn, epochs=1, validation_data=(X_test_rnn.reshape(-1, 1, 5), y_test_rnn), batch_size=5, verbose=1)\n",
    "\n",
    "    # Save the run information to register the model later\n",
    "    #kerasURI = run.info.artifact_uri\n",
    "\n",
    "    # Registrar los parámetros del modelo\n",
    "    mlflow.log_params({\n",
    "        \"input_shape\": (1, 5),\n",
    "        \"lstm_units\": 30,\n",
    "        \"dense_layers\": [60, 30, 15],\n",
    "        \"activation\": \"relu\",\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"loss_function\": \"mean_squared_error\",\n",
    "        \"epochs\": 1,\n",
    "        \"batch_size\": 5\n",
    "    })\n",
    "\n",
    "    # Registrar la estructura del modelo en MLflow\n",
    "    #mlflow.keras.log_model(model_rnn, \"keras_tf_v1\")\n",
    "\n",
    "    # VALIDACION \n",
    "    # Obtener la pérdida en el conjunto de entrenamiento y el conjunto de validación\n",
    "    train_loss = history.history['loss']\n",
    "    test_loss = history.history['val_loss']\n",
    "\n",
    "    # Calcular el RMSE en el conjunto de entrenamiento y el conjunto de validación\n",
    "    train_rmse = np.sqrt(train_loss)\n",
    "    test_rmse = np.sqrt(test_loss)\n",
    "\n",
    "    # Registro de métricas de RMSE\n",
    "    mlflow.log_metric(\"train_RMSE\", train_rmse[-1])  # Se registra el último valor de RMSE del conjunto de entrenamiento\n",
    "    mlflow.log_metric(\"test_RMSE\", test_rmse[-1])      # Se registra el último valor de RMSE del conjunto de validación\n",
    "    \n",
    "    # Crear gráfico de pérdida durante el entrenamiento\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "    plt.plot(epochs, train_loss, 'bo', label='Pérdida en entrenamiento')\n",
    "    plt.plot(epochs, test_loss, 'r', label='Pérdida en validación')\n",
    "    plt.title('Pérdida durante el entrenamiento y la validación')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Pérdida')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"kerasplotv3.png\")\n",
    "    mlflow.log_artifact(\"kerasplotv3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58f71112-0887-4995-8f0d-c0d4630afdfd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a79b6da-c1f2-484c-bc22-3648669d9926",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Register to Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5389f1ed-220b-423b-b0bd-b5cafc7687b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"Example_rnn\"                                  #nombre que se le dara al modelo que registraremos en el MlFlow Registry\n",
    "model_uri = f\"runs:/ed91e81d7ca644728f3e223fa3cfac92/model\" #identificador unico del experimento a registrar en Mlflow\n",
    "registered_model_version = mlflow.register_model(model_uri, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "619530ae-40b3-4869-98a7-127b2d1c330b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Load from Model Registry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa0c60a0-24ee-4d31-8071-a9e2d79c2070",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mlflow\n",
    "\n",
    "client = mlflow.tracking.MlflowClient() \n",
    "model_name = \"Example_rnn\"\n",
    "\n",
    "model_info = client.get_registered_model(model_name)\n",
    "model_version = model_info.latest_versions[0].version #Ultima version del modelo en MlFlow Registry\n",
    "#model_version = registered_model_version.version\n",
    "\n",
    "model = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{model_version}\")\n",
    "\n",
    "# Supongamos que tienes tus datos de entrada en una lista\n",
    "input_data = np.array([[12, 35, 129, 48, 129]])\n",
    "\n",
    "# # Convertir los datos de entrada al tipo de datos float64\n",
    "input_data = input_data.astype(np.float64)\n",
    "\n",
    "# # Aumentamos a 3dimensiones los datos de entrada para que tengan la forma (None, 1, 5)\n",
    "input_data = np.reshape(input_data, (input_data.shape[0], 1, input_data.shape[1]))\n",
    "\n",
    "# # Realiza la predicción utilizando el modelo\n",
    "model.predict(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e4f94afe-2d0f-44f6-bf78-295684c4fa64",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Load model without experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "517634c5-0f13-41b3-b6a3-5c068cab81c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_uri = f\"runs:/ed91e81d7ca644728f3e223fa3cfac92/model\"\n",
    "model = mlflow.pyfunc.load_model(model_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c6fdb49-999a-4307-9118-0d9e9c4482d9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Actualizar el modelo y tener una nueva version del Modelo de MlFlow Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd145bdb-01f7-4cfe-9b4b-fb47a7555f95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Definir el nombre del modelo y la nueva URI del modelo (para la versión 2)\n",
    "model_name = \"Example_rnn\"\n",
    "new_model_uri = 'runs:/3fdcef4bd83943ec9dc2188bc13045f4/model'  # Ejemplo de nueva URI del modelo\n",
    "\n",
    "# Registrar la nueva versión del modelo con la misma nombre pero con una nueva URI\n",
    "registered_model_version = mlflow.register_model(new_model_uri, model_name)\n",
    "\n",
    "# Si deseas, puedes obtener el ID de la nueva versión del modelo registrado\n",
    "new_version_id = registered_model_version.version\n",
    "new_version_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31f32055-1327-4ebf-8d14-da0d62db4686",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Validacion del Modelo antes de pasasr a Staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a7f866a-6e80-402a-9cd3-c772a3a4d917",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Obtener el modelo  in trancision, su nombre y version por el Webbook\n",
    "#model_name, model_version = fech_webbook_data()\n",
    "import mlflow\n",
    "# Interactuar con el servidor de MLflow\n",
    "client = mlflow.tracking.MlflowClient()  \n",
    "model_name = \"Example_rnn\"\n",
    "\n",
    "model_info = client.get_registered_model(model_name)\n",
    "model_version = model_info.latest_versions[0].version #Ultima version del modelo en MlFlow Registry\n",
    "\n",
    "models_details = client.get_model_version(model_name, model_version)\n",
    "run_info = client.get_run(run_id=models_details.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d968d96a-798a-472a-b561-dffe925f579e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "run_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39fcc6f2-bf68-44a7-a7ea-f97751d88083",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Validacion de la prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "297157fb-3cf6-454f-90bb-7160a761cda8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_store import FeatureStoreClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c89e0a88-eca8-4e5f-bb4f-9c99698f14b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_store import FeatureStoreClient\n",
    "\n",
    "fs = FeatureStoreClient()\n",
    "\n",
    "#Leer de Feature Store \n",
    "data_source = run_info.data.tags['db_table']\n",
    "features = fs.read_table(data_source)\n",
    "\n",
    "#Load model as a spark UDF\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "loaded_model = mlflow.pyfunc.spark_udf(spark, model_uri=model_uri)\n",
    "\n",
    "#Selecciona las columnas de la tabla de caracteristicas, por el esquema input del modelo\n",
    "input_columns_names = loaded_model.metadata.get_input_schema().input_names()\n",
    "\n",
    "#Predict in spark dataframe\n",
    "try:\n",
    "    display(features.withColumn('predictions', loaded_model(*input_columns_names)))\n",
    "    client.set_model_version_tag(name=model_name, version=model_version, key=\"predicts\", value=1)\n",
    "except Exception:\n",
    "    print(\"No se puede predecir las caracteristicas,\")\n",
    "    client.set_model_version_tag(name=model_name, version=model_version, key=\"predicts\", value=0)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95839cf5-8303-4d88-93c8-5595520545f0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Nombre del modelo registrado\n",
    "model_name = \"MLops_kerastf_v3\"\n",
    "\n",
    "# Crear una instancia del cliente de MLflow\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "# Obtener la información sobre el modelo\n",
    "model_info = client.get_registered_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d4e0541-3bd6-4846-a3a7-60e8ca68376b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c799774-d3e0-484b-b4a9-ab141e1d3aa9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Estado al que deseas cambiar el modelo (p. ej., \"Production\", \"Staging\", \"Archived\")\n",
    "new_stage = \"None\"\n",
    "\n",
    "# Versión específica que deseas cambiar de estado\n",
    "#target_version = model_info.latest_versions[0].version # ultima version del modelo registrado en mlflow registry\n",
    "target_version = 1\n",
    "\n",
    "\n",
    "# Cambiar el estado del modelo\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version = target_version,  #\n",
    "    stage=new_stage\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "000b9112-4079-480d-8f0b-d69fae5b8c8e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Estado al que deseas cambiar el modelo (p. ej., \"Production\", \"Staging\", \"Archived\")\n",
    "new_stage = \"Production\"\n",
    "\n",
    "# Cambiar el estado del modelo\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=model_info.latest_versions[0].version,\n",
    "    stage=new_stage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00ce886b-1c30-46b8-b132-11dc59e7f55c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Crear gráfico de pérdida durante el entrenamiento\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "plt.plot(epochs, train_loss, 'bo', label='Pérdida en entrenamiento')\n",
    "plt.plot(epochs, val_loss, 'r', label='Pérdida en validación')\n",
    "plt.title('Pérdida durante el entrenamiento y la validación')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3382b8d0-4ee8-47d8-8b6c-3ed5fd7a3ab2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Modelo 2 : Redes Tradicionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9853087a-3f70-496b-8680-adb720259e22",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Librerias para redes neuronales(LSTM)\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Normalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 3. Construccion del modelo de RED NEURONAL\n",
    "# Aseguramos que los resultados sean \"reproducibles\" en cada ejecucion de tensorflow(pesos iniciales aleatorios)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train_rnn, X_test_rnn, y_train_rnn, y_test_rnn = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Arquitectura 2:\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(Dense(15, activation='relu', input_shape=[5]))\n",
    "model_rnn.add(Dense(7, activation='relu'))\n",
    "model_rnn.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compilar el modelo\n",
    "model_rnn.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# Imprimir un resumen del modelo\n",
    "model_rnn.summary()\n",
    "\n",
    "# Entrenar el modelo\n",
    "# Red LSTM\n",
    "#history = model_rnn.fit(X_train_rnn.reshape(-1, 1, 5), y_train_rnn, epochs=5, validation_data=(X_test_rnn.reshape(-1, 1, 5),y_test_rnn), batch_size=5, verbose=1)\n",
    "# Red Tradicional\n",
    "history = model_rnn.fit(X_train_rnn, y_train_rnn, epochs=4, validation_data=(X_test_rnn,y_test_rnn), batch_size=5, verbose=1)\n",
    "\n",
    "# 4. Validacion del Modelo con la metrica de RSME\n",
    "# VALIDACION 1 del Modelo\n",
    "# Obtener la pérdida en el conjunto de entrenamiento y el conjunto de validación\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Calcular el RMSE en el conjunto de entrenamiento y el conjunto de validación\n",
    "train_rmse = np.sqrt(train_loss)\n",
    "val_rmse = np.sqrt(val_loss)\n",
    "\n",
    "# VALIDACION 2 del Modelo\n",
    "# Hacer predicciones en el conjunto de prueba Red LSTM\n",
    "#y_pred_rnn = model_rnn.predict(X_test_rnn.reshape(-1, 1, 5)) # (n_samples, n_pasos, n_variables)\n",
    "# Hacer predicciones en el conjunto de prueba Red Tradicional\n",
    "y_pred_rnn = model_rnn.predict(X_test_rnn) # (n_samples, n_pasos, n_variables)\n",
    "\n",
    "# Redondear los valores de y_pred al entero más cercano\n",
    "y_pred_rnn = np.round(y_pred_rnn).astype('int64')\n",
    "\n",
    "# Calcular el error cuadrático medio en el conjunto de prueba\n",
    "mse = mean_squared_error(y_test_rnn, y_pred_rnn)\n",
    "# Calcular la raíz cuadrada del error cuadrático medio\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'Raíz del Error Cuadrático Medio en el conjunto de prueba: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d303d06d-4296-4cbf-9b94-c563c6d2b313",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Crear gráfico de pérdida durante el entrenamiento\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "plt.plot(epochs, train_loss, 'bo', label='Pérdida en entrenamiento')\n",
    "plt.plot(epochs, val_loss, 'r', label='Pérdida en validación')\n",
    "plt.title('Pérdida durante el entrenamiento y la validación')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "532ddb61-3f2c-4052-87e3-24ef6df8efb1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "np.unique(y_pred_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b274f1da-e5a1-4bc8-90ce-f342a61bfd64",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Registrar un modelo en MLflow\n",
    "model_path = \"dbfs:/databricks/mlflow-tracking/8323b80e926241ee8763b7dc43085602/3fdcef4bd83943ec9dc2188bc13045f4/artifacts/model\"\n",
    "model_name = \"MLops_kerastf_v1\"\n",
    "mlflow.register_model(model_path, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9af3a01f-943e-4409-a614-592e3ecbd897",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#ver el directorio local de databrinks mas no el local de .os\n",
    "dbutils.fs.ls(\"dbfs:/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4df2356b-8582-4906-b953-ea2bfe0cb6ce",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Guardar Modelo en Azure Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "621d2c95-ecd2-4658-9469-93f93af1af77",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#1. Guardar en el directorio LOCAL (.OS)\n",
    "model_rnn.save('/nuevomodelo/modelrnn_nuevo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "349ed379-807a-458e-b837-b4a138358ce4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#2. Verificar que se ha guardado en el directorio LOCAL (.OS)\n",
    "import os\n",
    "os.listdir(\"/modelornn_version1_d4m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfe3bae1-24bd-403d-814c-b33f777e6516",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Opcion 1: Cargar el Modelo ML directamente del Directorio (.OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2765c5c1-8d8e-4046-94d0-e98a024dd08b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cargar el modelo desde el contenedor de almacenamiento Azure\n",
    "loaded_model_nuevo = tf.keras.models.load_model(\"/nuevomodelo/modelrnn_nuevo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2638681c-a02a-426e-94a6-2f5f05ed0417",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Opcion  2: Copiar el Modelo ML desde el Directorio LOCAL(.OS)  HASTA  Directorio de DBFS de Azure DataBrinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6020d49-aa50-46a7-8d59-618603e2d66b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#copie los datos desde LOCAL(.OS) a DBFS como dbfs (DIRECTORIO DE DATABRINKS)\n",
    "dbutils.fs.cp(\"file:/nuevomodelo/modelrnn_nuevo\", \"dbfs:/nuevomodelo/modelrnn_nuevo\", recurse=True) # True: si copias una carpeta, False: si #solo es archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87d7cef4-3479-4c9d-a1d8-674dfb543d9e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Verificar que se ha migrado desde Directorio LOCAL(.OS)  Hacia Directorio DBFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec38fcb3-0103-4181-b59e-303202ad9ee4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/nuevomodelo/modelrnn_nuevo\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb1bdbeb-327b-41b5-b064-35f2e75a04a4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Copiar el modelo desde el directorio DBFS al contenedor de almacenamiento Azure Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f7d3187-f0c7-498a-88a7-5960e258d7d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Copiar el modelo desde el directorio DBFS al contenedor de almacenamiento Azure Storage\n",
    "dbutils.fs.cp(\"/nuevomodelo/modelrnn_nuevo\", \"/mnt/datalakemlopsd4m/presentation/modelrnn_nuevo\", recurse=True) #True:Copycarpeta,#False:Copyarchivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68462a76-164b-4caf-ae33-62dd7be082c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import mlflow.tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # Establecer la URI de seguimiento de MLflow\n",
    "# mlflow.set_tracking_uri(\"databricks\")  # Usa \"databricks\" para Databricks\n",
    "\n",
    "# # Crear un nuevo experimento si no existe\n",
    "# experiment_name = \"nombre_del_experimento\"\n",
    "# mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Cargar los datos\n",
    "df_delta = spark.read.format(\"delta\").load(\"/mnt/datalakemlopsd4m/presentation/datmarcobre_fengineer_tablacaract_delta\")\n",
    "datos = df_delta.toPandas()\n",
    "\n",
    "# Separar las variables independientes y dependiente\n",
    "X = datos[['capacidad_en_volumen_equipo_carguio_m3',\n",
    "           'capacidad_en_peso_equipo_carguio',\n",
    "           'capacidad_en_peso_equipo_acarreo',\n",
    "           'densidad_inicial_poligono_creado_tn/m3',\n",
    "           'capacidad_en_volumen_equipo_acarreo_m3']].values\n",
    "y = datos['numero_pases_carguio'].values\n",
    "\n",
    "# Construir el modelo de red neuronal\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "X_train_rnn, X_test_rnn, y_train_rnn, y_test_rnn = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "mlflow.tensorflow.autolog()  # Keras y TensorFlow\n",
    "\n",
    "# Entrenar el modelo\n",
    "with mlflow.start_run(run_name='experimento_mlflow_keras_tf_3_21_24'):  #Iniciliza un nuevo experimento de MlFlow\n",
    "    model_rnn = Sequential()\n",
    "    model_rnn.add(LSTM(30, activation='relu', input_shape=(1, 5)))\n",
    "    model_rnn.add(Dense(60, activation='relu'))\n",
    "    model_rnn.add(Dense(30, activation='relu'))\n",
    "    model_rnn.add(Dense(15, activation='relu'))\n",
    "    model_rnn.add(Dense(1, activation='linear'))\n",
    "\n",
    "    model_rnn.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    history = model_rnn.fit(X_train_rnn.reshape(-1, 1, 5), y_train_rnn, epochs=1, \n",
    "                            validation_data=(X_test_rnn.reshape(-1, 1, 5), y_test_rnn), \n",
    "                            batch_size=5, verbose=1)\n",
    "\n",
    "    # Registrar los parámetros del modelo\n",
    "    mlflow.log_params({\n",
    "        \"input_shape\": (1, 5),\n",
    "        \"lstm_units\": 30,\n",
    "        \"dense_layers\": [60, 30, 15],\n",
    "        \"activation\": \"relu\",\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"loss_function\": \"mean_squared_error\",\n",
    "        \"epochs\": 1,\n",
    "        \"batch_size\": 5\n",
    "    })\n",
    "\n",
    "    # Registrar la estructura del modelo en MLflow\n",
    "    mlflow.keras.log_model(model_rnn, \"keras_tf_3_21_24\")\n",
    "\n",
    "    # Calcular métricas\n",
    "    train_loss = history.history['loss']\n",
    "    test_loss = history.history['val_loss']\n",
    "    train_rmse = np.sqrt(train_loss)\n",
    "    test_rmse = np.sqrt(test_loss)\n",
    "\n",
    "    # Registrar métricas de RMSE\n",
    "    mlflow.log_metric(\"train_RMSE\", train_rmse[-1])\n",
    "    mlflow.log_metric(\"test_RMSE\", test_rmse[-1])\n",
    "\n",
    "    # Crear gráfico de pérdida durante el entrenamiento\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "    plt.plot(epochs, train_loss, 'bo', label='Pérdida en entrenamiento')\n",
    "    plt.plot(epochs, test_loss, 'r', label='Pérdida en validación')\n",
    "    plt.title('Pérdida durante el entrenamiento y la validación')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Pérdida')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"kerasplot_3_21_24.png\")\n",
    "    mlflow.log_artifact(\"kerasplot_3_21_24.png\")\n",
    "\n",
    "    # Obtener la ruta del modelo registrado\n",
    "    model_path = mlflow.get_artifact_uri(\"keras_tf_3_21_24\")\n",
    "\n",
    "# Registrar el modelo en MLflow\n",
    "model_name = \"MLops_kerastf_3_21_24\"\n",
    "mlflow.register_model(model_path, model_name)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4.model_developer",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
